{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Code to Extract Title, Description, and URL from API"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wall time: 1.63 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "import os\n",
    "import requests\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import nltk\n",
    "import datetime\n",
    "from nltk.tag import StanfordNERTagger\n",
    "\n",
    "\n",
    "# import sys # import \n",
    "# !{sys.executable} -m pip install polyglot\n",
    "# nltk.download('words')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "news = [\n",
    "        'bloomberg', 'reuters', 'financial-times',\n",
    "        'the-economist', 'the-wall-street-journal', 'cnbc',\n",
    "        ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wall time: 6.49 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "news_d = {}\n",
    "\n",
    "for i in news:\n",
    "    \n",
    "    \"\"\"\n",
    "    Reads in the API request of the top headlines to clean the JSON data to only return the source, title, and description\n",
    "    \"\"\"\n",
    "    \n",
    "    url = ('https://newsapi.org/v2/top-headlines?'\n",
    "           'sources=' + i + '&'\n",
    "           'apiKey=ddcb36b8f0d645b0acd4a54ef804a9fe')\n",
    "    \n",
    "    response = requests.get(url)\n",
    "    \n",
    "    news_d[i] = []\n",
    "    \n",
    "    for x in range(0, len(response.json()['articles'])):\n",
    "        article_title = response.json()['articles'][x]['title']\n",
    "        article_description = response.json()['articles'][x]['description']\n",
    "        \n",
    "        news_d[i].append({'title': article_title, 'description': article_description})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wall time: 0 ns\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "def create_d(dictionary):\n",
    "    source_list = [] \n",
    "    title_list = []\n",
    "    description_list = []\n",
    "    \n",
    "    \"\"\"\n",
    "    Takes in the cleaned news dictionary to turn it into an acceptable format for pandas.\n",
    "    1. Check if there are any news articles for that selected news site.\n",
    "    2. Appends the source (e.g. bloomberg) then the article's title and description to the above list\n",
    "    \"\"\"\n",
    "\n",
    "    for i in news_d:\n",
    "        if bool(news_d[i]):\n",
    "            \n",
    "            for x in range(0, len(news_d[i])):\n",
    "                source_list.append(i)\n",
    "                title_list.append(news_d[i][x]['title'])\n",
    "                description_list.append(news_d[i][x]['description'])\n",
    "    \n",
    "    d = {'source': source_list,\n",
    "         'title': title_list,\n",
    "         'description': description_list,\n",
    "        }\n",
    "    \n",
    "    return d"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wall time: 2.02 ms\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "data = create_d(news_d)\n",
    "df = pd.DataFrame(data=data)\n",
    "df = df[['source', 'title', 'description']]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## AI Attempt\n",
    "\n",
    "Reference to the following blog:\n",
    "http://blog.chartbeat.com/2015/10/22/identifying-and-clustering-news-events-by-content/\n",
    "\n",
    "And also reference to Jose Portilla's Natural Language Processing course in his Python for Data Science and Machine Learning Bootcamp Course on Udemy:\n",
    "https://www.udemy.com/python-for-data-science-and-machine-learning-bootcamp/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wall time: 0 ns\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "import string\n",
    "from nltk.corpus import stopwords"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wall time: 0 ns\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "def text_process(mess):\n",
    "    \"\"\"\n",
    "    Takes in a string of text, then performs the following:\n",
    "    1. Remove all punctuation\n",
    "    2. Remove all stopwords\n",
    "    3. Returns a list of the cleaned text\n",
    "    \"\"\"\n",
    "    \n",
    "    # Check if the cell has characters inside\n",
    "    if mess is not None:\n",
    "\n",
    "        # Check characters to see if they are in punctuation\n",
    "        nohyph = mess.replace('-', ' ')\n",
    "        nopunc = nohyph.replace(\"’s\", ' ')\n",
    "        nopunc = nopunc.replace(\"’\", ' ')\n",
    "        nopunc = nopunc.replace(\"‘\", ' ')\n",
    "        nopunc = [char for char in nopunc if char not in string.punctuation]\n",
    "        \n",
    "\n",
    "\n",
    "        # Join the characters again to form the string.\n",
    "        nopunc = ''.join(nopunc)\n",
    "\n",
    "        # Now just remove any stopwords\n",
    "        word_list = [word for word in nopunc.split() if word.lower() not in stopwords.words('english')]\n",
    "        \n",
    "        return ' '.join(word_list)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## TF-IDF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wall time: 0 ns\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.metrics.pairwise import cosine_similarity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wall time: 835 ms\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "df['details'] = df['title'].astype(str) + ' ' + df['description'].astype(str)\n",
    "df['details'] = df['details'].apply(text_process)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wall time: 11 ms\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "vectorizer = TfidfVectorizer(stop_words='english')\n",
    "X = vectorizer.fit_transform(df['details'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wall time: 9.99 ms\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "sim = cosine_similarity(X)\n",
    "sim_matrix = pd.DataFrame(sim, columns = list(df['title']), index = list(df['title']))\n",
    "sim_matrix[sim_matrix >= 0.18] = 1\n",
    "sim_matrix[sim_matrix < 0.18] = 0\n",
    "sim_matrix = sim_matrix.reset_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wall time: 183 ms\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "clusters = []\n",
    "\n",
    "while len(sim_matrix) > 0:\n",
    "    summation = list(sim_matrix.sum(axis=1))\n",
    "    ind = summation.index(max(summation))\n",
    "\n",
    "    titles = list(sim_matrix.columns[(sim_matrix == 1).iloc[ind]])\n",
    "    index_title = sim_matrix['index'][ind]\n",
    "    titles.append(index_title)\n",
    "    titles = list(set(titles))\n",
    "    clusters.append(titles)\n",
    "\n",
    "    sim_matrix = sim_matrix.drop(titles, axis=1)\n",
    "    for title in titles:\n",
    "        sim_matrix = sim_matrix[sim_matrix['index'] != title]\n",
    "\n",
    "    sim_matrix = sim_matrix.reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[['Theresa May Faces Crisis Over Brexit After Key Ministers Quit',\n",
       "  'UK PM May should not face a leadership challenge: ex-Brexit minister Davis',\n",
       "  'UK Brexit Secretary David Davis resigns, source tells Reuters',\n",
       "  \"UK's ex-Brexit minister Davis says not calling for other resignations\",\n",
       "  \"Denouncing 'dangerous strategy', Brexit minister quits in blow to May\",\n",
       "  'UK government in disarray as Davis resigns as Brexit secretary',\n",
       "  'U.K. Minister in Charge of Brexit Negotiations Resigns'],\n",
       " [\"After Pyongyang put-down, Pompeo stands by 'difficult' denuclearization talks\",\n",
       "  'North Korea presents nuclear disarmament’s biggest challenge yet',\n",
       "  \"North Korea Reminds Trump Its Nuclear Weapons Won't Come Cheap\"],\n",
       " ['Operation to rescue boys trapped in Thai cave resumes: officials',\n",
       "  'Four Boys Rescued From Flooded Thai Cave',\n",
       "  'Operation to rescue boys trapped in Thai cave resumes'],\n",
       " ['Chinese Smartphone Maker Xiaomi Falls in Hong Kong Trading Debut',\n",
       "  'Shares of Chinese smartphone maker Xiaomi open for trade below IPO price',\n",
       "  \"Xiaomi's weak debut portends trouble for imminent Hong Kong tech listings\"],\n",
       " ['U.K. Opens Murder Probe After Woman Exposed to Nerve Agent Dies',\n",
       "  'UK woman dies after poisoning by Soviet-era nerve agent'],\n",
       " [\"Democrats are tying Trump's Supreme Court pick to the special counsel's Russia probe. Here's why\",\n",
       "  'Trump Takes a Final Look at Supreme Court Choices'],\n",
       " ['For China, Tech Giant Tencent Is Both a National Champion and a Threat',\n",
       "  'Chinese tech giant Tencent plans to list its online music business in the United States'],\n",
       " ['American Steak and German Cars: Early Trade War Victims Emerge'],\n",
       " ['Russia Should Admit It Uses Mercenaries'],\n",
       " [\"Here's One Area Where Russia Beats the U.S.\"],\n",
       " ['World Bank CEO Adds to Voices of Worry Over Global Debt Pileup'],\n",
       " ['Canada’s Labor Force Grows Most in 6 Years, Raising Jobless Rate'],\n",
       " ['What’s Next for Hotelier After Buying the Trump Toronto? America'],\n",
       " ['Trudeau Says Nothing ‘Untoward’ Led to Past Groping Allegation'],\n",
       " ['Canada Strikes Back at Trump, and Condo Buyers Will Pay the Price'],\n",
       " ['Global stocks hit two-week high as U.S. jobs report spreads relief'],\n",
       " ['Myanmar court presses secrets act charges against Reuters reporters'],\n",
       " ['Trump-Putin face nuclear options at Helsinki summit'],\n",
       " ['‘A good living but a rough life’: trucker shortage holds US economy back'],\n",
       " ['US banks count on tax cut windfall to boost profits'],\n",
       " ['Apple slices into Spotify’s lead in US music market'],\n",
       " ['Japan is nervous about its energy security'],\n",
       " ['Italy’s debts to European Central Bank near €500bn'],\n",
       " ['BlackRock and Citi plan Paris expansion in Macron coup'],\n",
       " ['Yelp’s Jeremy Stoppelman on his Big Tech fightback'],\n",
       " ['Explainer: issues at the heart of May’s soft-Brexit Chequers deal'],\n",
       " ['Why bitcoin uses so much energy'],\n",
       " ['A court with a solid conservative majority could reshape American life'],\n",
       " ['Ukraine wants a national church that is not beholden to Moscow'],\n",
       " ['The boss of Pakistan’s ruling party is sentenced to ten years in jail'],\n",
       " ['Italy’s government proposes to limit fixed-term job contracts'],\n",
       " ['Tomorrow’s squadron leaders will be accompanied by drones'],\n",
       " ['Japan is finally starting to admit more foreign workers'],\n",
       " ['Culture and the labour market keep India’s women at home'],\n",
       " ['Transgender identities: a series of invited essays'],\n",
       " ['Summit Looms for a Strained NATO Alliance'],\n",
       " ['Stock Buybacks Are Booming, but Share Prices Aren’t Budging'],\n",
       " ['How U.S. and China Tariffs Are Rippling Through U.S. Industries'],\n",
       " ['Miss America Organization Split by #MeToo Era Swimsuit Decision'],\n",
       " ['Consumer companies, desperate for growth, drove dealmaking to a 15-year high in 2017'],\n",
       " ['The US is facing soaring trade deficits, but rising energy prices are a bigger danger'],\n",
       " [\"Two nominees are now Trump's greatest focus for top court, NBC News says\"],\n",
       " ['Oil is likely to jump another 10 percent this summer, energy expert Tom Kloza predicts'],\n",
       " [\"Amazon's purchase of Whole Foods flipped the meal kit industry upside down; celebrity spokesmodels, football stars help sell vegan dinners\"],\n",
       " ['Silicon Valley firms are facing a rise in anger from a new source: Their own employees']]"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clusters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
