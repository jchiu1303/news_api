{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Code to Extract Title, Description, and URL from API"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import requests\n",
    "import pandas as pd\n",
    "import datetime\n",
    "import string\n",
    "\n",
    "from nltk.tag import StanfordNERTagger\n",
    "from nltk.corpus import stopwords\n",
    "\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "\n",
    "# import sys # import \n",
    "# !{sys.executable} -m pip install polyglot\n",
    "# nltk.download('words')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "news = [\n",
    "        'bloomberg', 'reuters', 'financial-times',\n",
    "        'the-economist', 'the-wall-street-journal', 'cnbc',\n",
    "        'financial-post', 'business-insider', 'google-news', \n",
    "        'fortune', 'bbc-news',\n",
    "        ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "\n",
    "news_d = {}\n",
    "\n",
    "for i in news:\n",
    "    \n",
    "    \"\"\"\n",
    "    Reads in the API request of the top headlines to clean the JSON data to only return the source, title, and description\n",
    "    \"\"\"\n",
    "    \n",
    "    url = ('https://newsapi.org/v2/top-headlines?'\n",
    "           'sources=' + i + '&'\n",
    "           'apiKey=ddcb36b8f0d645b0acd4a54ef804a9fe')\n",
    "    \n",
    "    response = requests.get(url)\n",
    "    \n",
    "    news_d[i] = []\n",
    "    \n",
    "    for x in range(0, len(response.json()['articles'])):\n",
    "        article_title = response.json()['articles'][x]['title']\n",
    "        article_description = response.json()['articles'][x]['description']\n",
    "        \n",
    "        news_d[i].append({'title': article_title, 'description': article_description})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_d(dictionary):\n",
    "    source_list = [] \n",
    "    title_list = []\n",
    "    description_list = []\n",
    "    \n",
    "    \"\"\"\n",
    "    Takes in the cleaned news dictionary to turn it into an acceptable format for pandas.\n",
    "    1. Check if there are any news articles for that selected news site.\n",
    "    2. Appends the source (e.g. bloomberg) then the article's title and description to the above list\n",
    "    \"\"\"\n",
    "\n",
    "    for i in news_d:\n",
    "        if bool(news_d[i]):\n",
    "            \n",
    "            for x in range(0, len(news_d[i])):\n",
    "                source_list.append(i)\n",
    "                title_list.append(news_d[i][x]['title'])\n",
    "                description_list.append(news_d[i][x]['description'])\n",
    "    \n",
    "    d = {'source': source_list,\n",
    "         'title': title_list,\n",
    "         'description': description_list,\n",
    "        }\n",
    "    \n",
    "    return d"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = create_d(news_d)\n",
    "df = pd.DataFrame(data=data)\n",
    "df = df[['source', 'title', 'description']]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## AI Attempt\n",
    "\n",
    "Reference to the following blog:\n",
    "http://blog.chartbeat.com/2015/10/22/identifying-and-clustering-news-events-by-content/\n",
    "\n",
    "And also reference to Jose Portilla's Natural Language Processing course in his Python for Data Science and Machine Learning Bootcamp Course on Udemy:\n",
    "https://www.udemy.com/python-for-data-science-and-machine-learning-bootcamp/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def text_process(mess):\n",
    "    \"\"\"\n",
    "    Takes in a string of text, then performs the following:\n",
    "    1. Remove all punctuation\n",
    "    2. Remove all stopwords\n",
    "    3. Returns a list of the cleaned text\n",
    "    \"\"\"\n",
    "    \n",
    "    # Check if the cell has characters inside\n",
    "    if mess is not None:\n",
    "\n",
    "        # Check characters to see if they are in punctuation\n",
    "        nohyph = mess.replace('-', ' ')\n",
    "        nopunc = nohyph.replace(\"’s\", ' ')\n",
    "        nopunc = nopunc.replace(\"’\", ' ')\n",
    "        nopunc = nopunc.replace(\"‘\", ' ')\n",
    "        nopunc = [char for char in nopunc if char not in string.punctuation]\n",
    "        \n",
    "\n",
    "\n",
    "        # Join the characters again to form the string.\n",
    "        nopunc = ''.join(nopunc)\n",
    "\n",
    "        # Now just remove any stopwords\n",
    "        word_list = [word for word in nopunc.split() if word.lower() not in stopwords.words('english')]\n",
    "        \n",
    "        return ' '.join(word_list)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## TF-IDF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['details'] = df['title'].astype(str) + ' ' + df['description'].astype(str)\n",
    "# df['details'] = df['title'].astype(str)\n",
    "df['details'] = df['details'].apply(text_process)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "vectorizer = TfidfVectorizer(stop_words='english')\n",
    "X = vectorizer.fit_transform(df['details'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Cosine Similarity Matrix\n",
    "\n",
    "Referencing to method in this blog post: https://ematosevic.wordpress.com/2016/08/21/clustering-data-with-similarity-matrix-in-python-tutorial/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "parameter = 0.2\n",
    "\n",
    "sim = cosine_similarity(X)\n",
    "sim_matrix = pd.DataFrame(sim, columns = list(df['title']), index = list(df['title']))\n",
    "sim_matrix[sim_matrix >= parameter] = 1\n",
    "sim_matrix[sim_matrix < parameter] = 0\n",
    "sim_matrix = sim_matrix.reset_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "clusters = []\n",
    "\n",
    "while len(sim_matrix) > 0:\n",
    "    summation = list(sim_matrix.sum(axis=1))\n",
    "    ind = summation.index(max(summation))\n",
    "\n",
    "    titles = list(sim_matrix.columns[(sim_matrix == 1).iloc[ind]])\n",
    "    index_title = sim_matrix['index'][ind]\n",
    "    titles.append(index_title)\n",
    "    titles = list(set(titles))\n",
    "    clusters.append(titles)\n",
    "\n",
    "    sim_matrix = sim_matrix.drop(titles, axis=1)\n",
    "    for title in titles:\n",
    "        sim_matrix = sim_matrix[sim_matrix['index'] != title]\n",
    "\n",
    "    sim_matrix = sim_matrix.reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "for cluster in clusters:\n",
    "    if len(cluster) > 1:\n",
    "        for i in cluster:\n",
    "            print(i)\n",
    "        print('=====================')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "current_time = datetime.datetime.now().strftime(\"%Y%m%d_%H%M%S\")\n",
    "df.to_csv('data/{}_input-parameter-('.format(current_time) + str(parameter) + ').csv', sep=',', encoding='utf-8', index=False)\n",
    "\n",
    "clusters_df = pd.DataFrame(clusters, columns = range(1, len(clusters[0])+1))\n",
    "clusters_df.to_csv('data/{}_output-parameter-('.format(current_time) + str(parameter) + ').csv', sep=',', encoding='utf-8', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
